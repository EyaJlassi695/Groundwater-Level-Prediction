{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DveeEol_SMk"
      },
      "source": [
        "# Necessary library installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EgDKKhdrmoNV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autogluon in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2)\n",
            "Requirement already satisfied: autogluon.core==1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core[all]==1.2->autogluon) (1.2)\n",
            "Requirement already satisfied: autogluon.features==1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon) (1.2)\n",
            "Requirement already satisfied: autogluon.tabular==1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (1.2)\n",
            "Requirement already satisfied: autogluon.multimodal==1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon) (1.2)\n",
            "Requirement already satisfied: autogluon.timeseries==1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries[all]==1.2->autogluon) (1.2)\n",
            "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.25.2)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.9.3)\n",
            "Requirement already satisfied: scikit-learn<1.5.3,>=1.4.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.5.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.2)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.67.0)\n",
            "Requirement already satisfied: requests in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.9.2)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.35.82)\n",
            "Requirement already satisfied: autogluon.common==1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.2)\n",
            "Requirement already satisfied: ray<2.40,>=2.10.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.10.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core[all]==1.2->autogluon) (18.1.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.core[all]==1.2->autogluon) (0.2.7)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (11.0.0)\n",
            "Requirement already satisfied: torch<2.6,>=2.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.5.1)\n",
            "Requirement already satisfied: lightning<2.6,>=2.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.4.0)\n",
            "Requirement already satisfied: transformers<5,>=4.38.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (4.47.1)\n",
            "Requirement already satisfied: accelerate<1.0,>=0.34.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.34.2)\n",
            "Requirement already satisfied: jsonschema<4.22,>=4.18 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (4.21.1)\n",
            "Requirement already satisfied: seqeval<1.3.0,>=1.2.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.2.2)\n",
            "Requirement already satisfied: evaluate<0.5.0,>=0.4.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.4.3)\n",
            "Requirement already satisfied: timm<1.0.7,>=0.9.5 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.0.3)\n",
            "Requirement already satisfied: torchvision<0.21.0,>=0.16.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.20.1)\n",
            "Requirement already satisfied: scikit-image<0.25.0,>=0.19.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.24.0)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.3)\n",
            "Requirement already satisfied: torchmetrics<1.3.0,>=1.2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.2.1)\n",
            "Requirement already satisfied: omegaconf<2.3.0,>=2.1.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.2.3)\n",
            "Requirement already satisfied: pytorch-metric-learning<2.4,>=1.3.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.3.0)\n",
            "Requirement already satisfied: nlpaug<1.2.0,>=1.1.10 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.1.11)\n",
            "Requirement already satisfied: nltk<3.9,>=3.4.5 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (3.8.1)\n",
            "Requirement already satisfied: openmim<0.4.0,>=0.3.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.3.9)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (3.1.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (2.18.0)\n",
            "Requirement already satisfied: pytesseract<0.3.11,>=0.3.9 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (0.3.10)\n",
            "Requirement already satisfied: nvidia-ml-py3==7.352.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (7.352.0)\n",
            "Requirement already satisfied: pdf2image<1.19,>=1.17.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.multimodal==1.2->autogluon) (1.17.0)\n",
            "Requirement already satisfied: catboost<1.3,>=1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (1.2.7)\n",
            "Requirement already satisfied: spacy<3.8 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (3.7.5)\n",
            "Requirement already satisfied: lightgbm<4.6,>=4.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (4.5.0)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (0.8.0)\n",
            "Requirement already satisfied: xgboost<2.2,>=1.6 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (2.1.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (2.7.18)\n",
            "Requirement already satisfied: huggingface-hub[torch] in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.tabular[all]==1.2->autogluon) (0.27.0)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.2)\n",
            "Requirement already satisfied: pytorch-lightning in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.4.0)\n",
            "Requirement already satisfied: gluonts<0.17,>=0.15.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.16.0)\n",
            "Requirement already satisfied: statsforecast<1.8,>=1.7.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.7.8)\n",
            "Requirement already satisfied: mlforecast==0.13.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.13.4)\n",
            "Requirement already satisfied: utilsforecast<0.2.5,>=0.2.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.2.4)\n",
            "Requirement already satisfied: coreforecast==0.0.12 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.0.12)\n",
            "Requirement already satisfied: fugue>=0.9.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.9.1)\n",
            "Requirement already satisfied: orjson~=3.9 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.10.12)\n",
            "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (6.1.0)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.1.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2024.9.0)\n",
            "Requirement already satisfied: numba in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.60.0)\n",
            "Requirement already satisfied: optuna in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.1.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (24.2)\n",
            "Requirement already satisfied: window-ops in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.0.15)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate<1.0,>=0.34.0->autogluon.multimodal==1.2->autogluon) (0.4.5)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.82 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.35.82)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.10.4)\n",
            "Requirement already satisfied: graphviz in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (0.20.3)\n",
            "Requirement already satisfied: plotly in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (1.16.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon) (3.2.0)\n",
            "Requirement already satisfied: dill in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon) (0.3.8)\n",
            "Requirement already satisfied: xxhash in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.2->autogluon) (0.70.16)\n",
            "Requirement already satisfied: pip in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (24.3.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (1.7.27)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.2->autogluon) (1.0.3)\n",
            "Requirement already satisfied: triad>=0.9.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.9.8)\n",
            "Requirement already satisfied: adagio>=0.2.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.2.6)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.10.4)\n",
            "Requirement already satisfied: toolz~=0.10 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (4.12.2)\n",
            "Requirement already satisfied: future in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon) (1.0.0)\n",
            "Requirement already satisfied: py4j in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2->autogluon) (0.10.9.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.2->autogluon) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.2->autogluon) (0.21.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (0.11.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.2->autogluon) (2024.11.6)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.2->autogluon) (4.9.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.4.6)\n",
            "Requirement already satisfied: model-index in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.0.10)\n",
            "Requirement already satisfied: rich in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.16.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.29.1)\n",
            "Requirement already satisfied: aiosignal in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (3.11.7)\n",
            "Requirement already satisfied: aiohttp-cors in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.7.0)\n",
            "Requirement already satisfied: colorful in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.0)\n",
            "Requirement already satisfied: opencensus in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.11.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.21.0)\n",
            "Requirement already satisfied: smart-open in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (7.0.5)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (20.28.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.68.1)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.6.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (2024.8.30)\n",
            "Requirement already satisfied: imageio>=2.33 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (2024.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image<0.25.0,>=0.19.1->autogluon.multimodal==1.2->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.core==1.2->autogluon.core[all]==1.2->autogluon) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.15.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (65.5.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.14.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (2.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.2->autogluon) (3.1.3)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.multimodal==1.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5,>=4.38.0->transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (0.21.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[sentencepiece]<5,>=4.38.0->autogluon.multimodal==1.2->autogluon) (0.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.4.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.18.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (4.12.3)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.27.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels>=0.13.2->statsforecast<1.8,>=1.7.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.0.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.1.5)\n",
            "Requirement already satisfied: fs in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.4.16)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (2.18.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.3.6)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (0.20.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.17.0)\n",
            "Requirement already satisfied: ordered-set in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (4.1.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.24.0)\n",
            "Requirement already satisfied: pycryptodome in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (3.21.0)\n",
            "Requirement already satisfied: openxlab in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.0.11)\n",
            "Requirement already satisfied: pywin32 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (308)\n",
            "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.14.0)\n",
            "Requirement already satisfied: colorlog in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (2.0.36)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.2->autogluon) (9.0.0)\n",
            "Requirement already satisfied: Mako in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.3.8)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (1.25.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (2.37.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]==1.2->autogluon) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.2->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->mlforecast==0.13.4->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (3.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (2.6)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.2->autogluon.timeseries[all]==1.2->autogluon) (1.4.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.2->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2->autogluon) (0.6.1)\n",
            "Requirement already satisfied: dask in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2024.12.1)\n",
            "Requirement already satisfied: click>=8.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (0.12.1)\n",
            "Requirement already satisfied: importlib_metadata>=4.13.0 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dask) (8.5.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.1->dask) (0.4.6)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib_metadata>=4.13.0->dask) (3.21.0)\n",
            "Requirement already satisfied: locket in c:\\users\\jlassi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from partd>=1.4.0->dask) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "# Installation of AutoML SOTA library and dask\n",
        "!pip install autogluon\n",
        "!pip install dask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVf5lacE_ZNn"
      },
      "source": [
        "# Some simple Feature Engineering and Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEEP1jxo2W-F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from autogluon.tabular  import TabularDataset, TabularPredictor\n",
        "\n",
        "\n",
        "X_train = pd.read_csv('X_train_Hi5.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = pd.read_csv('X_test_Hi5.csv',low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "Final_predi=pd.read_csv(\"y_test_Hi5.csv\", delimiter=',')\n",
        " # This is the file that contains the predictions of the models that we have trained in the previous steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test=Final_predi['piezo_groundwater_level_category'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3ytF3Lv02W-F"
      },
      "outputs": [],
      "source": [
        "# Remove columns with a missing rate higher than 50%\n",
        "missing_rates = X_train.isnull().mean()\n",
        "columns_to_keep = missing_rates[missing_rates <= 0.5].index\n",
        "\n",
        "X_train=X_train[columns_to_keep[1:]]\n",
        "X_test = X_test[columns_to_keep[1:-1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfsb2XMY2W-H",
        "outputId": "217ec225-0c7a-41dd-a16c-e5e6e1664d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "insee_%_agri              float64\n",
            "insee_pop_commune         float64\n",
            "insee_med_living_level    float64\n",
            "insee_%_ind               float64\n",
            "insee_%_const             float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Convert INSEE columns to float64 data type\n",
        "insee_columns = X_train.filter(regex='^insee_').columns\n",
        "X_train[insee_columns] = X_train[insee_columns].apply(pd.to_numeric, errors='coerce')\n",
        "X_test[insee_columns] = X_test[insee_columns].apply(pd.to_numeric, errors='coerce')\n",
        "print(X_train[insee_columns].dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8AvFtd432W-G"
      },
      "outputs": [],
      "source": [
        "non_numeric_cols = X_test.select_dtypes(include=['object', 'category']).columns\n",
        "time_cols = [col for col in X_train.columns if 'date' in col.lower()]\n",
        "categorical_cols = [col for col in non_numeric_cols if col not in time_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mWAgXETV9lM9"
      },
      "outputs": [],
      "source": [
        "# Define some preprocessing functions\n",
        "def date(df):\n",
        "    df['piezo_measurement_date'] = pd.to_datetime(df['piezo_measurement_date'])\n",
        "    df['year'] = df['piezo_measurement_date'].dt.year\n",
        "    df['month'] = df['piezo_measurement_date'].dt.month\n",
        "    df['day'] = df['piezo_measurement_date'].dt.day\n",
        "    df = df.drop(columns=['piezo_measurement_date'])\n",
        "    return df\n",
        "\n",
        "def engineer_features(df):\n",
        "\n",
        "    for window in [7, 14]:\n",
        "        df[f'temp_avg_{window}d'] = df.groupby('piezo_station_bss_code')['meteo_temperature_avg'] \\\n",
        "            .rolling(window=window, min_periods=1) \\\n",
        "            .mean() \\\n",
        "            .reset_index(0, drop=True)\n",
        "\n",
        "        df[f'rain_sum_{window}d'] = df.groupby('piezo_station_bss_code')['meteo_rain_height'] \\\n",
        "            .rolling(window=window, min_periods=1) \\\n",
        "            .sum() \\\n",
        "            .reset_index(0, drop=True)\n",
        "    df['rain_temp_interaction'] = df['meteo_rain_height'] * df['meteo_temperature_avg']\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rf0yrZTG2W-G"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['piezo_station_update_date', 'meteo_date', 'hydro_observation_date_elab']\n",
        "X_train = X_train.drop(columns=columns_to_drop)\n",
        "X_test = X_test.drop(columns=columns_to_drop)\n",
        "\n",
        "# DateTime preprocessing\n",
        "X_train=date(X_train)\n",
        "X_test=date(X_test)\n",
        "\n",
        "# Preliminary Feature Engineering\n",
        "X_train=engineer_features(X_train)\n",
        "X_test=engineer_features(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "VAyySVnT2W-H"
      },
      "outputs": [],
      "source": [
        "non_numeric_cols = X_test.select_dtypes(include=['object', 'category']).columns\n",
        "numeric_cols=X_train.select_dtypes(include=['number']).columns\n",
        "time_cols = [col for col in X_train.columns if 'date' in col.lower()]\n",
        "categorical_cols = [col for col in non_numeric_cols if col not in time_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTXgTx2O2W-H",
        "outputId": "a2b7386f-44c1-4aed-f29f-261da92c745f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(X_train[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(X_test[col].median(), inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna('nan', inplace=True)\n",
            "C:\\Users\\JLASSI\\AppData\\Local\\Temp\\ipykernel_3464\\1619863657.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna('nan', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "for col in numeric_cols:\n",
        "    X_train[col].fillna(X_train[col].median(), inplace=True)\n",
        "    X_test[col].fillna(X_test[col].median(), inplace=True)\n",
        "for col in categorical_cols:\n",
        "    X_train[col].fillna('nan', inplace=True)\n",
        "    X_test[col].fillna('nan', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkUWKd_YAVH3"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "piezo_station_department_code         object\n",
            "piezo_station_investigation_depth    float64\n",
            "piezo_station_department_name         object\n",
            "piezo_station_commune_code_insee      object\n",
            "piezo_station_pe_label                object\n",
            "                                      ...   \n",
            "temp_avg_7d                          float64\n",
            "rain_sum_7d                          float64\n",
            "temp_avg_14d                         float64\n",
            "rain_sum_14d                         float64\n",
            "rain_temp_interaction                float64\n",
            "Length: 95, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(X_train.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-01-01 20:14:43,035] A new study created in memory with name: no-name-32a4e645-9630-472c-9db4-833669e472c0\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_191443\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       13.15 GB / 39.32 GB (33.4%)\n",
            "Disk Space Avail:   180.19 GB / 449.47 GB (40.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    19588.15 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (41.8% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 41.8% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.8s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.3s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.6s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.8s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t64.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 21 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 22 | ['__nlp__.327', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.conseil', '__nlp__.de', ...]\n",
            "\t\t\t106.3s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 22 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 22 | ['__nlp__.327', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.conseil', '__nlp__.de', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 22 | ['__nlp__.327', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.conseil', '__nlp__.de', ...]\n",
            "\t\t\t3.3s = Fit runtime\n",
            "\t\t\t133 features in original data used to generate 133 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t13 duplicate columns removed: ['piezo_continuity_name', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 14 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.de', '__nlp__.de la', '__nlp__.des', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 14 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.de', '__nlp__.de la', '__nlp__.des', ...]\n",
            "\t\t\t2.6s = Fit runtime\n",
            "\t\t\t120 features in original data used to generate 120 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 14 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.de', '__nlp__.de la', '__nlp__.des', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 14 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.de', '__nlp__.de la', '__nlp__.des', ...]\n",
            "\t208.4s = Fit runtime\n",
            "\t87 features in original data used to generate 120 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1508.87 MB (5.9% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 215.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.28333206115755916, 'subsample': 0.5198366253240017, 'colsample_bytree': 0.8522255121629868}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.28333206115755916, 'subsample': 0.5198366253240017, 'colsample_bytree': 0.8522255121629868, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n",
            "\tWarning: Potentially not enough memory to safely train model. Estimated to require 13.154 GB out of 16.809 GB available memory (78.256%)... (100.000% of avail memory is the max safe size)\n",
            "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.09 to avoid the warning)\n",
            "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
            "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.56643\tvalidation_0-_f1_weighted:-0.33302\n",
            "[50]\tvalidation_0-mlogloss:1.20327\tvalidation_0-_f1_weighted:-0.54159\n",
            "[100]\tvalidation_0-mlogloss:1.10023\tvalidation_0-_f1_weighted:-0.59996\n",
            "[150]\tvalidation_0-mlogloss:1.02983\tvalidation_0-_f1_weighted:-0.63421\n",
            "[177]\tvalidation_0-mlogloss:0.99427\tvalidation_0-_f1_weighted:-0.65219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.6522\t = Validation score   (f1_weighted)\n",
            "\t401.44s\t = Training   runtime\n",
            "\t0.49s\t = Validation runtime\n",
            "\t57225.6\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.6522\t = Validation score   (f1_weighted)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t56540.1\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 623.48s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 56540.1 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_191443\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 20:25:45,512] Trial 0 finished with value: inf and parameters: {'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.28333206115755916, 'subsample': 0.5198366253240017, 'colsample_bytree': 0.8522255121629868}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_192545\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       19.08 GB / 39.32 GB (48.5%)\n",
            "Disk Space Avail:   184.06 GB / 449.47 GB (41.0%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    25838.74 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (31.7% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 31.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.1s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.6s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.5s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.3s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t75.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 22 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 23 | ['__nlp__.327', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.conseil', '__nlp__.conseil gnral', ...]\n",
            "\t\t\t104.4s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 23 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 23 | ['__nlp__.327', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.conseil', '__nlp__.conseil gnral', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 23 | ['__nlp__.327', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.conseil', '__nlp__.conseil gnral', ...]\n",
            "\t\t\t4.8s = Fit runtime\n",
            "\t\t\t134 features in original data used to generate 134 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t13 duplicate columns removed: ['piezo_continuity_name', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 15 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.conseil gnral', '__nlp__.de', '__nlp__.de la', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 15 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.conseil gnral', '__nlp__.de', '__nlp__.de la', ...]\n",
            "\t\t\t3.6s = Fit runtime\n",
            "\t\t\t121 features in original data used to generate 121 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 15 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.conseil gnral', '__nlp__.de', '__nlp__.de la', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 15 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.conseil gnral', '__nlp__.de', '__nlp__.de la', ...]\n",
            "\t221.7s = Fit runtime\n",
            "\t87 features in original data used to generate 121 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1514.26 MB (5.8% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 228.36s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.10341540276087575, 'subsample': 0.6953492698535233, 'colsample_bytree': 0.5710642068792053}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.10341540276087575, 'subsample': 0.6953492698535233, 'colsample_bytree': 0.5710642068792053, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n",
            "\tWarning: Potentially not enough memory to safely train model. Estimated to require 13.534 GB out of 17.412 GB available memory (77.730%)... (100.000% of avail memory is the max safe size)\n",
            "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.09 to avoid the warning)\n",
            "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
            "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.57540\tvalidation_0-_f1_weighted:-0.42503\n",
            "[50]\tvalidation_0-mlogloss:0.99715\tvalidation_0-_f1_weighted:-0.71147\n",
            "[100]\tvalidation_0-mlogloss:0.86415\tvalidation_0-_f1_weighted:-0.75259\n",
            "[109]\tvalidation_0-mlogloss:0.85171\tvalidation_0-_f1_weighted:-0.75648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.7565\t = Validation score   (f1_weighted)\n",
            "\t406.87s\t = Training   runtime\n",
            "\t0.73s\t = Validation runtime\n",
            "\t38626.9\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.7565\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t37848.8\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 642.81s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 37848.8 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_192545\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 20:37:11,635] Trial 1 finished with value: inf and parameters: {'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.10341540276087575, 'subsample': 0.6953492698535233, 'colsample_bytree': 0.5710642068792053}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_193711\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.17 GB / 39.32 GB (51.3%)\n",
            "Disk Space Avail:   181.00 GB / 449.47 GB (40.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    26739.01 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (30.6% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 30.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.1s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.6s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.7s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.6s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t77.5s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 31 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t107.4s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 32 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.2s = Fit runtime\n",
            "\t\t\t143 features in original data used to generate 143 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t17 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.2s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t236.0s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 244.58s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.017399033017341844, 'subsample': 0.8129252343680653, 'colsample_bytree': 0.549104751431082}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.017399033017341844, 'subsample': 0.8129252343680653, 'colsample_bytree': 0.549104751431082, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60597\tvalidation_0-_f1_weighted:-0.36357\n",
            "[50]\tvalidation_0-mlogloss:1.48378\tvalidation_0-_f1_weighted:-0.47441\n",
            "[100]\tvalidation_0-mlogloss:1.40605\tvalidation_0-_f1_weighted:-0.50004\n",
            "[141]\tvalidation_0-mlogloss:1.36038\tvalidation_0-_f1_weighted:-0.51125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.5113\t = Validation score   (f1_weighted)\n",
            "\t376.17s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "\t71588.5\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.5113\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t69380.0\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 627.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 69380.0 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_193711\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 20:48:09,482] Trial 2 finished with value: inf and parameters: {'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.017399033017341844, 'subsample': 0.8129252343680653, 'colsample_bytree': 0.549104751431082}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_194809\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.53 GB / 39.32 GB (54.7%)\n",
            "Disk Space Avail:   174.28 GB / 449.47 GB (38.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    28172.15 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.0% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.0% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.4s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.3s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.3s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t3.8s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t51.2s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 31 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t67.7s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 32 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t3.5s = Fit runtime\n",
            "\t\t\t143 features in original data used to generate 143 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t17 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t2.9s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t153.8s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 160.23s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 105, 'max_depth': 9, 'learning_rate': 0.2127554830062797, 'subsample': 0.840473447691428, 'colsample_bytree': 0.869902346383334}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 105, 'max_depth': 9, 'learning_rate': 0.2127554830062797, 'subsample': 0.840473447691428, 'colsample_bytree': 0.869902346383334, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.54742\tvalidation_0-_f1_weighted:-0.41228\n",
            "[50]\tvalidation_0-mlogloss:0.97479\tvalidation_0-_f1_weighted:-0.68662\n",
            "[100]\tvalidation_0-mlogloss:0.87250\tvalidation_0-_f1_weighted:-0.72950\n",
            "[104]\tvalidation_0-mlogloss:0.86401\tvalidation_0-_f1_weighted:-0.73338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.7334\t = Validation score   (f1_weighted)\n",
            "\t226.68s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "\t70193.1\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.7334\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t68493.1\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 392.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 68493.1 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_194809\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 20:55:11,180] Trial 3 finished with value: inf and parameters: {'n_estimators': 105, 'max_depth': 9, 'learning_rate': 0.2127554830062797, 'subsample': 0.840473447691428, 'colsample_bytree': 0.869902346383334}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_195511\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.65 GB / 39.32 GB (55.1%)\n",
            "Disk Space Avail:   178.45 GB / 449.47 GB (39.7%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    28306.22 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (28.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 28.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.3s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.3s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.3s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t3.7s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t49.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 30 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t68.7s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t4.1s = Fit runtime\n",
            "\t\t\t142 features in original data used to generate 142 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t16 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.3s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t155.1s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.7% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 161.61s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.09924404188725143, 'subsample': 0.5942159901131452, 'colsample_bytree': 0.5979175091324209}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.09924404188725143, 'subsample': 0.5942159901131452, 'colsample_bytree': 0.5979175091324209, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60122\tvalidation_0-_f1_weighted:-0.28396\n",
            "[50]\tvalidation_0-mlogloss:1.46330\tvalidation_0-_f1_weighted:-0.36249\n",
            "[93]\tvalidation_0-mlogloss:1.42857\tvalidation_0-_f1_weighted:-0.38255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.3826\t = Validation score   (f1_weighted)\n",
            "\t263.76s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "\t80336.3\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.3826\t = Validation score   (f1_weighted)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t76866.1\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 431.89s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 76866.1 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_195511\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 21:03:00,928] Trial 4 finished with value: inf and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.09924404188725143, 'subsample': 0.5942159901131452, 'colsample_bytree': 0.5979175091324209}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_200300\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.14 GB / 39.32 GB (51.2%)\n",
            "Disk Space Avail:   176.25 GB / 449.47 GB (39.2%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    26802.71 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (30.5% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 30.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.9s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.6s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t78.2s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 28 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 29 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t111.5s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 29 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 29 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 29 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.2s = Fit runtime\n",
            "\t\t\t140 features in original data used to generate 140 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t14 duplicate columns removed: ['piezo_continuity_name', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.2s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t242.3s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.8% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 250.86s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 117, 'max_depth': 7, 'learning_rate': 0.01077918958877841, 'subsample': 0.5852912093564604, 'colsample_bytree': 0.8743263273155503}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 117, 'max_depth': 7, 'learning_rate': 0.01077918958877841, 'subsample': 0.5852912093564604, 'colsample_bytree': 0.8743263273155503, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60708\tvalidation_0-_f1_weighted:-0.36692\n",
            "[50]\tvalidation_0-mlogloss:1.51380\tvalidation_0-_f1_weighted:-0.43772\n",
            "[100]\tvalidation_0-mlogloss:1.45017\tvalidation_0-_f1_weighted:-0.45462\n",
            "[116]\tvalidation_0-mlogloss:1.43345\tvalidation_0-_f1_weighted:-0.45945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.4595\t = Validation score   (f1_weighted)\n",
            "\t451.63s\t = Training   runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "\t55977.9\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.4595\t = Validation score   (f1_weighted)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t54333.5\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 709.14s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 54333.5 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_200300\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 21:15:31,571] Trial 5 finished with value: inf and parameters: {'n_estimators': 117, 'max_depth': 7, 'learning_rate': 0.01077918958877841, 'subsample': 0.5852912093564604, 'colsample_bytree': 0.8743263273155503}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_201531\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.68 GB / 39.32 GB (52.6%)\n",
            "Disk Space Avail:   174.63 GB / 449.47 GB (38.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27347.94 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.8s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.9s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.5s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t76.9s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 29 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t107.8s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 30 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.2s = Fit runtime\n",
            "\t\t\t141 features in original data used to generate 141 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t15 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.4s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t237.5s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.6% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 245.99s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.011304420424717023, 'subsample': 0.8392377374852149, 'colsample_bytree': 0.8310358951901835}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.011304420424717023, 'subsample': 0.8392377374852149, 'colsample_bytree': 0.8310358951901835, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60745\tvalidation_0-_f1_weighted:-0.34307\n",
            "[50]\tvalidation_0-mlogloss:1.52882\tvalidation_0-_f1_weighted:-0.40021\n",
            "[100]\tvalidation_0-mlogloss:1.47616\tvalidation_0-_f1_weighted:-0.41887\n",
            "[150]\tvalidation_0-mlogloss:1.43665\tvalidation_0-_f1_weighted:-0.43212\n",
            "[189]\tvalidation_0-mlogloss:1.41250\tvalidation_0-_f1_weighted:-0.44037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.4404\t = Validation score   (f1_weighted)\n",
            "\t467.75s\t = Training   runtime\n",
            "\t0.43s\t = Validation runtime\n",
            "\t66219.2\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.4404\t = Validation score   (f1_weighted)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t64558.1\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 721.01s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 64558.1 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_201531\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 21:28:03,125] Trial 6 finished with value: inf and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.011304420424717023, 'subsample': 0.8392377374852149, 'colsample_bytree': 0.8310358951901835}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_202803\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.44 GB / 39.32 GB (54.5%)\n",
            "Disk Space Avail:   172.83 GB / 449.47 GB (38.5%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    28080.23 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.1% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.8s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.9s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.6s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t8.0s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.3s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t75.9s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 29 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t108.5s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 30 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t141 features in original data used to generate 141 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t15 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.3s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t229.4s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.6% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 236.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 73, 'max_depth': 4, 'learning_rate': 0.013764619508066952, 'subsample': 0.6967629599700602, 'colsample_bytree': 0.7332584819288946}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 73, 'max_depth': 4, 'learning_rate': 0.013764619508066952, 'subsample': 0.6967629599700602, 'colsample_bytree': 0.7332584819288946, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60798\tvalidation_0-_f1_weighted:-0.30512\n",
            "[50]\tvalidation_0-mlogloss:1.54940\tvalidation_0-_f1_weighted:-0.34338\n",
            "[72]\tvalidation_0-mlogloss:1.53164\tvalidation_0-_f1_weighted:-0.34795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.3479\t = Validation score   (f1_weighted)\n",
            "\t227.19s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "\t88535.0\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.3479\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "\t87311.6\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 470.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 87311.6 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_202803\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 21:36:29,584] Trial 7 finished with value: inf and parameters: {'n_estimators': 73, 'max_depth': 4, 'learning_rate': 0.013764619508066952, 'subsample': 0.6967629599700602, 'colsample_bytree': 0.7332584819288946}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_203629\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.00 GB / 39.32 GB (53.4%)\n",
            "Disk Space Avail:   171.01 GB / 449.47 GB (38.0%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27775.98 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.5% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.9s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.7s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.4s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t76.2s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 29 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t109.5s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 30 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 30 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t4.9s = Fit runtime\n",
            "\t\t\t141 features in original data used to generate 141 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t15 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.3s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t237.0s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.7% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 245.49s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.03789805515024451, 'subsample': 0.5512268002402971, 'colsample_bytree': 0.7091769173153081}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.03789805515024451, 'subsample': 0.5512268002402971, 'colsample_bytree': 0.7091769173153081, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60187\tvalidation_0-_f1_weighted:-0.36514\n",
            "[50]\tvalidation_0-mlogloss:1.38382\tvalidation_0-_f1_weighted:-0.48957\n",
            "[100]\tvalidation_0-mlogloss:1.28702\tvalidation_0-_f1_weighted:-0.52939\n",
            "[150]\tvalidation_0-mlogloss:1.23165\tvalidation_0-_f1_weighted:-0.55481\n",
            "[154]\tvalidation_0-mlogloss:1.22818\tvalidation_0-_f1_weighted:-0.55593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.5559\t = Validation score   (f1_weighted)\n",
            "\t480.49s\t = Training   runtime\n",
            "\t0.58s\t = Validation runtime\n",
            "\t49211.2\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.5559\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t48242.2\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 733.82s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 48242.2 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_203629\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 21:49:27,790] Trial 8 finished with value: inf and parameters: {'n_estimators': 155, 'max_depth': 7, 'learning_rate': 0.03789805515024451, 'subsample': 0.5512268002402971, 'colsample_bytree': 0.7091769173153081}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_204927\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.68 GB / 39.32 GB (52.6%)\n",
            "Disk Space Avail:   168.78 GB / 449.47 GB (37.6%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27355.94 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t8.2s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.4s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t77.3s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 28 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 29 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t108.6s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 29 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 29 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 29 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t140 features in original data used to generate 140 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t14 duplicate columns removed: ['piezo_continuity_name', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.0s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t239.1s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.7% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 247.75s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 196, 'max_depth': 4, 'learning_rate': 0.05865036092250103, 'subsample': 0.5631876320329252, 'colsample_bytree': 0.5006901694852518}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 196, 'max_depth': 4, 'learning_rate': 0.05865036092250103, 'subsample': 0.5631876320329252, 'colsample_bytree': 0.5006901694852518, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60376\tvalidation_0-_f1_weighted:-0.28329\n",
            "[50]\tvalidation_0-mlogloss:1.46727\tvalidation_0-_f1_weighted:-0.38011\n",
            "[100]\tvalidation_0-mlogloss:1.41502\tvalidation_0-_f1_weighted:-0.40392\n",
            "[150]\tvalidation_0-mlogloss:1.38257\tvalidation_0-_f1_weighted:-0.42479\n",
            "[195]\tvalidation_0-mlogloss:1.36197\tvalidation_0-_f1_weighted:-0.43859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.4386\t = Validation score   (f1_weighted)\n",
            "\t463.49s\t = Training   runtime\n",
            "\t0.46s\t = Validation runtime\n",
            "\t62191.5\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.4386\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t60150.6\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 718.77s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 60150.6 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_204927\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 22:02:06,325] Trial 9 finished with value: inf and parameters: {'n_estimators': 196, 'max_depth': 4, 'learning_rate': 0.05865036092250103, 'subsample': 0.5631876320329252, 'colsample_bytree': 0.5006901694852518}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_210206\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.65 GB / 39.32 GB (55.1%)\n",
            "Disk Space Avail:   163.35 GB / 449.47 GB (36.3%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    28314.65 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (28.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 28.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.5s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.6s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t8.4s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.3s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t75.8s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 31 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t107.7s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 32 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.1s = Fit runtime\n",
            "\t\t\t143 features in original data used to generate 143 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t17 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.3s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t235.9s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 244.4s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.2669944581696004, 'subsample': 0.9997136210942211, 'colsample_bytree': 0.980905284638035}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.2669944581696004, 'subsample': 0.9997136210942211, 'colsample_bytree': 0.980905284638035, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.57120\tvalidation_0-_f1_weighted:-0.31393\n",
            "[50]\tvalidation_0-mlogloss:1.28608\tvalidation_0-_f1_weighted:-0.48602\n",
            "[100]\tvalidation_0-mlogloss:1.20377\tvalidation_0-_f1_weighted:-0.53575\n",
            "[150]\tvalidation_0-mlogloss:1.14739\tvalidation_0-_f1_weighted:-0.56410\n",
            "[162]\tvalidation_0-mlogloss:1.13323\tvalidation_0-_f1_weighted:-0.57116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.5712\t = Validation score   (f1_weighted)\n",
            "\t388.68s\t = Training   runtime\n",
            "\t0.49s\t = Validation runtime\n",
            "\t58175.8\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.5712\t = Validation score   (f1_weighted)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t56272.5\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 639.39s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 56272.5 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_210206\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 22:13:26,814] Trial 10 finished with value: inf and parameters: {'n_estimators': 163, 'max_depth': 5, 'learning_rate': 0.2669944581696004, 'subsample': 0.9997136210942211, 'colsample_bytree': 0.980905284638035}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_211326\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.30 GB / 39.32 GB (54.2%)\n",
            "Disk Space Avail:   166.72 GB / 449.47 GB (37.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    28095.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.1% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.9s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t8.2s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.3s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t77.6s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 30 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t112.2s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t142 features in original data used to generate 142 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t16 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.5s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t241.5s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 249.89s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.11459704609780862, 'subsample': 0.6897623420019515, 'colsample_bytree': 0.6554007822680478}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.11459704609780862, 'subsample': 0.6897623420019515, 'colsample_bytree': 0.6554007822680478, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.57021\tvalidation_0-_f1_weighted:-0.43683\n",
            "[50]\tvalidation_0-mlogloss:0.96461\tvalidation_0-_f1_weighted:-0.71544\n",
            "[54]\tvalidation_0-mlogloss:0.94838\tvalidation_0-_f1_weighted:-0.72102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.721\t = Validation score   (f1_weighted)\n",
            "\t254.36s\t = Training   runtime\n",
            "\t0.44s\t = Validation runtime\n",
            "\t64811.1\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.721\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t62965.5\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 511.82s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 62965.5 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_211326\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 22:22:39,198] Trial 11 finished with value: inf and parameters: {'n_estimators': 55, 'max_depth': 10, 'learning_rate': 0.11459704609780862, 'subsample': 0.6897623420019515, 'colsample_bytree': 0.6554007822680478}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_212239\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.61 GB / 39.32 GB (55.0%)\n",
            "Disk Space Avail:   159.55 GB / 449.47 GB (35.5%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    28336.63 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (28.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 28.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.8s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.6s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t8.0s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.6s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.7s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t75.2s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 31 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t108.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 32 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.4s = Fit runtime\n",
            "\t\t\t143 features in original data used to generate 143 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t17 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.4s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t235.4s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 243.79s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 133, 'max_depth': 9, 'learning_rate': 0.16274545068774085, 'subsample': 0.5108717108327563, 'colsample_bytree': 0.8042810900689524}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 133, 'max_depth': 9, 'learning_rate': 0.16274545068774085, 'subsample': 0.5108717108327563, 'colsample_bytree': 0.8042810900689524, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.56092\tvalidation_0-_f1_weighted:-0.41161\n",
            "[50]\tvalidation_0-mlogloss:1.00973\tvalidation_0-_f1_weighted:-0.67579\n",
            "[100]\tvalidation_0-mlogloss:0.91671\tvalidation_0-_f1_weighted:-0.71338\n",
            "[132]\tvalidation_0-mlogloss:0.87007\tvalidation_0-_f1_weighted:-0.73114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.7311\t = Validation score   (f1_weighted)\n",
            "\t397.57s\t = Training   runtime\n",
            "\t0.59s\t = Validation runtime\n",
            "\t47766.4\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.7311\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t46659.8\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 647.99s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 46659.8 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_212239\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 22:34:08,039] Trial 12 finished with value: inf and parameters: {'n_estimators': 133, 'max_depth': 9, 'learning_rate': 0.16274545068774085, 'subsample': 0.5108717108327563, 'colsample_bytree': 0.8042810900689524}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_213408\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.33 GB / 39.32 GB (54.3%)\n",
            "Disk Space Avail:   164.62 GB / 449.47 GB (36.6%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27949.12 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.3% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.3% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.4s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.4s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.0s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t74.2s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 33 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t106.8s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 34 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.3s = Fit runtime\n",
            "\t\t\t145 features in original data used to generate 145 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t19 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.de calais 265', '__nlp__.gologique rgional nord', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.6s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t230.6s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.3% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 238.78s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 175, 'max_depth': 8, 'learning_rate': 0.06321146177468995, 'subsample': 0.6670132484724962, 'colsample_bytree': 0.9361658722963054}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 175, 'max_depth': 8, 'learning_rate': 0.06321146177468995, 'subsample': 0.6670132484724962, 'colsample_bytree': 0.9361658722963054, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.59245\tvalidation_0-_f1_weighted:-0.38967\n",
            "[50]\tvalidation_0-mlogloss:1.24468\tvalidation_0-_f1_weighted:-0.56547\n",
            "[100]\tvalidation_0-mlogloss:1.14372\tvalidation_0-_f1_weighted:-0.60898\n",
            "[150]\tvalidation_0-mlogloss:1.09370\tvalidation_0-_f1_weighted:-0.63214\n",
            "[174]\tvalidation_0-mlogloss:1.07674\tvalidation_0-_f1_weighted:-0.63928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.6393\t = Validation score   (f1_weighted)\n",
            "\t512.65s\t = Training   runtime\n",
            "\t0.66s\t = Validation runtime\n",
            "\t43150.6\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.6393\t = Validation score   (f1_weighted)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t42247.6\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 758.4s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 42247.6 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_213408\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 22:47:31,138] Trial 13 finished with value: inf and parameters: {'n_estimators': 175, 'max_depth': 8, 'learning_rate': 0.06321146177468995, 'subsample': 0.6670132484724962, 'colsample_bytree': 0.9361658722963054}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_214731\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.75 GB / 39.32 GB (55.3%)\n",
            "Disk Space Avail:   163.49 GB / 449.47 GB (36.4%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    28009.89 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.2% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.2% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.5s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t8.1s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.3s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t78.1s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 33 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t107.1s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 34 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.1s = Fit runtime\n",
            "\t\t\t145 features in original data used to generate 145 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t19 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.de calais 265', '__nlp__.gologique rgional nord', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.5s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t240.0s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.3% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 248.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 91, 'max_depth': 10, 'learning_rate': 0.030959052519481833, 'subsample': 0.9369427489847639, 'colsample_bytree': 0.6497406843962775}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 91, 'max_depth': 10, 'learning_rate': 0.030959052519481833, 'subsample': 0.9369427489847639, 'colsample_bytree': 0.6497406843962775, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.59864\tvalidation_0-_f1_weighted:-0.43692\n",
            "[50]\tvalidation_0-mlogloss:1.26265\tvalidation_0-_f1_weighted:-0.64664\n",
            "[90]\tvalidation_0-mlogloss:1.13096\tvalidation_0-_f1_weighted:-0.68061\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.6806\t = Validation score   (f1_weighted)\n",
            "\t389.61s\t = Training   runtime\n",
            "\t0.55s\t = Validation runtime\n",
            "\t51057.3\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.6806\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t49753.7\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 645.2s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 49753.7 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_214731\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 22:58:58,103] Trial 14 finished with value: inf and parameters: {'n_estimators': 91, 'max_depth': 10, 'learning_rate': 0.030959052519481833, 'subsample': 0.9369427489847639, 'colsample_bytree': 0.6497406843962775}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_215858\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       21.13 GB / 39.32 GB (53.7%)\n",
            "Disk Space Avail:   160.04 GB / 449.47 GB (35.6%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    29383.70 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (27.8% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 27.8% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.1s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.5s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.6s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.5s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t74.3s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 30 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t105.6s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 31 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.1s = Fit runtime\n",
            "\t\t\t142 features in original data used to generate 142 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t16 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.2s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t230.0s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.6% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 238.27s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.1264248915544524, 'subsample': 0.639179258343656, 'colsample_bytree': 0.7825089353395098}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.1264248915544524, 'subsample': 0.639179258343656, 'colsample_bytree': 0.7825089353395098, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n",
            "\tWarning: Potentially not enough memory to safely train model. Estimated to require 13.434 GB out of 17.590 GB available memory (76.372%)... (100.000% of avail memory is the max safe size)\n",
            "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.07 to avoid the warning)\n",
            "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
            "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.58916\tvalidation_0-_f1_weighted:-0.34496\n",
            "[50]\tvalidation_0-mlogloss:1.29227\tvalidation_0-_f1_weighted:-0.49763\n",
            "[100]\tvalidation_0-mlogloss:1.22060\tvalidation_0-_f1_weighted:-0.53825\n",
            "[120]\tvalidation_0-mlogloss:1.19964\tvalidation_0-_f1_weighted:-0.55122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.5512\t = Validation score   (f1_weighted)\n",
            "\t351.59s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "\t71447.4\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.5512\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t69024.5\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 597.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 69024.5 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_215858\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 23:09:34,857] Trial 15 finished with value: inf and parameters: {'n_estimators': 121, 'max_depth': 6, 'learning_rate': 0.1264248915544524, 'subsample': 0.639179258343656, 'colsample_bytree': 0.7825089353395098}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_220934\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.23 GB / 39.32 GB (51.4%)\n",
            "Disk Space Avail:   157.34 GB / 449.47 GB (35.0%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    26900.14 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (30.4% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 30.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.5s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.6s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.4s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t76.1s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 31 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t104.2s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 32 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t143 features in original data used to generate 143 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t17 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.2s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t231.3s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.5% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 239.38s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 144, 'max_depth': 8, 'learning_rate': 0.29215583898093733, 'subsample': 0.7701185475452882, 'colsample_bytree': 0.6858306553700689}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 144, 'max_depth': 8, 'learning_rate': 0.29215583898093733, 'subsample': 0.7701185475452882, 'colsample_bytree': 0.6858306553700689, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n",
            "\tWarning: Potentially not enough memory to safely train model. Estimated to require 13.583 GB out of 17.650 GB available memory (76.955%)... (100.000% of avail memory is the max safe size)\n",
            "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.08 to avoid the warning)\n",
            "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
            "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.54272\tvalidation_0-_f1_weighted:-0.39108\n",
            "[50]\tvalidation_0-mlogloss:1.01566\tvalidation_0-_f1_weighted:-0.65381\n",
            "[100]\tvalidation_0-mlogloss:0.90116\tvalidation_0-_f1_weighted:-0.70696\n",
            "[143]\tvalidation_0-mlogloss:0.82919\tvalidation_0-_f1_weighted:-0.73735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.7373\t = Validation score   (f1_weighted)\n",
            "\t417.91s\t = Training   runtime\n",
            "\t0.55s\t = Validation runtime\n",
            "\t51887.0\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.7373\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "\t50465.7\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 664.01s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 50465.7 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_220934\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 23:21:15,417] Trial 16 finished with value: inf and parameters: {'n_estimators': 144, 'max_depth': 8, 'learning_rate': 0.29215583898093733, 'subsample': 0.7701185475452882, 'colsample_bytree': 0.6858306553700689}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_222115\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.75 GB / 39.32 GB (52.8%)\n",
            "Disk Space Avail:   157.79 GB / 449.47 GB (35.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27292.99 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (30.0% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 30.0% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.9s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.5s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.3s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.5s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.3s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t59.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 33 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t108.9s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 34 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.6s = Fit runtime\n",
            "\t\t\t145 features in original data used to generate 145 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t19 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.de calais 265', '__nlp__.gologique rgional nord', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t2.8s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t207.0s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 213.72s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.08203559062021856, 'subsample': 0.7464547084560876, 'colsample_bytree': 0.5895669862895457}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.08203559062021856, 'subsample': 0.7464547084560876, 'colsample_bytree': 0.5895669862895457, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.59867\tvalidation_0-_f1_weighted:-0.32626\n",
            "[50]\tvalidation_0-mlogloss:1.39389\tvalidation_0-_f1_weighted:-0.42757\n",
            "[100]\tvalidation_0-mlogloss:1.32825\tvalidation_0-_f1_weighted:-0.46467\n",
            "[150]\tvalidation_0-mlogloss:1.29256\tvalidation_0-_f1_weighted:-0.48691\n",
            "[173]\tvalidation_0-mlogloss:1.27953\tvalidation_0-_f1_weighted:-0.49673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.4967\t = Validation score   (f1_weighted)\n",
            "\t352.29s\t = Training   runtime\n",
            "\t0.53s\t = Validation runtime\n",
            "\t53288.9\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.4967\t = Validation score   (f1_weighted)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t51875.4\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 571.41s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 51875.4 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_222115\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 23:31:27,082] Trial 17 finished with value: inf and parameters: {'n_estimators': 174, 'max_depth': 5, 'learning_rate': 0.08203559062021856, 'subsample': 0.7464547084560876, 'colsample_bytree': 0.5895669862895457}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_223127\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.76 GB / 39.32 GB (52.8%)\n",
            "Disk Space Avail:   156.37 GB / 449.47 GB (34.8%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27394.78 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.0s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t4.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.5s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t7.6s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t5.6s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.6s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t73.5s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 33 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t109.0s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 34 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t5.2s = Fit runtime\n",
            "\t\t\t145 features in original data used to generate 145 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t19 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.de calais 265', '__nlp__.gologique rgional nord', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t4.3s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t233.5s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 242.01s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.1878951491203623, 'subsample': 0.615812079726711, 'colsample_bytree': 0.9223884369721738}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.1878951491203623, 'subsample': 0.615812079726711, 'colsample_bytree': 0.9223884369721738, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.56190\tvalidation_0-_f1_weighted:-0.38918\n",
            "[50]\tvalidation_0-mlogloss:1.09378\tvalidation_0-_f1_weighted:-0.62391\n",
            "[73]\tvalidation_0-mlogloss:1.04061\tvalidation_0-_f1_weighted:-0.64981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.6498\t = Validation score   (f1_weighted)\n",
            "\t223.89s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "\t87203.9\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.6498\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t83424.4\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 472.7s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 83424.4 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223127\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 23:39:49,570] Trial 18 finished with value: inf and parameters: {'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.1878951491203623, 'subsample': 0.615812079726711, 'colsample_bytree': 0.9223884369721738}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_223949\"\n",
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "GPU Count:          0\n",
            "Memory Avail:       20.89 GB / 39.32 GB (53.1%)\n",
            "Disk Space Avail:   153.40 GB / 449.47 GB (34.1%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'verbosity': 3}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': False,\n",
            " 'calibrate': 'auto',\n",
            " 'delay_bag_sets': False,\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_callbacks': False,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': None,\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': False,\n",
            " 'learning_curves': False,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': None,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'raise_on_no_models_fitted': True,\n",
            " 'refit_full': False,\n",
            " 'save_bag_folds': None,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': False,\n",
            " 'test_data': None,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\predictor.pkl\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27609.14 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.6% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t\t\t('object', 'object') : 30 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('object', [])       : 28 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.7s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])        : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool'])    :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t3.4s = Fit runtime\n",
            "\t\t\t92 features in original data used to generate 92 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])       :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['bool']) :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t0.4s = Fit runtime\n",
            "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t0.3s = Fit runtime\n",
            "\t\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', [])       : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                   : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t5.5s = Fit runtime\n",
            "\t\t\t28 features in original data used to generate 28 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('float', ['text_special']) : 12 | ['piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', 'piezo_station_pe_label.special_ratio', 'piezo_station_pe_label.symbol_ratio. ', ...]\n",
            "\t\t\t\t\t('int', ['text_special'])   :  8 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.symbol_count. ', 'piezo_station_pe_label.symbol_count.-', 'piezo_producer_name.char_count', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 20 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t4.0s = Fit runtime\n",
            "\t\t\t\t20 features in original data used to generate 20 features in processed data.\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t\t1 duplicate columns removed: ['piezo_producer_name.symbol_count. ']\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t0.4s = Fit runtime\n",
            "\t\t\t\t19 features in original data used to generate 19 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t53.3s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 19 features in processed data.\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\tCountVectorizer(dtype=<class 'numpy.uint8'>, max_features=10000, min_df=30,\n",
            "                ngram_range=(1, 3))\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 33 to avoid OOM error\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', ['text']) : 2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('int', ['text_ngram']) : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t70.6s = Fit runtime\n",
            "\t\t\t2 features in original data used to generate 34 features in processed data.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 26 | ['piezo_station_department_code', 'piezo_station_department_name', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  3 | ['piezo_continuity_code', 'piezo_continuity_name', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 34 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.aquitaine', '__nlp__.aquitaine 327', ...]\n",
            "\t\t\t3.5s = Fit runtime\n",
            "\t\t\t145 features in original data used to generate 145 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t19 duplicate columns removed: ['piezo_continuity_name', '__nlp__.calais', '__nlp__.calais 265', '__nlp__.de calais', '__nlp__.de calais 265', '__nlp__.gologique rgional nord', '__nlp__.aquitaine', '__nlp__.aquitaine 327', '__nlp__.gologique rgional aquitaine', '__nlp__.rgional aquitaine', '__nlp__.rgional aquitaine 327', '__nlp__.gnral', '__nlp__.gologique rgional', '__nlp__.service gologique', '__nlp__.service gologique rgional', 'piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_measure_nature_name']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t\t2.9s = Fit runtime\n",
            "\t\t\t126 features in original data used to generate 126 features in processed data.\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int32', 'int')     :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')     :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('object', 'object') : 25 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') : 24 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_pe_label', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', ...]\n",
            "\t\t('float64', 'float')     : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int32', 'int')         :  3 | ['year', 'month', 'day']\n",
            "\t\t('int64', 'int')         :  4 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code']\n",
            "\t\t('int8', 'int')          :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('uint16', 'int')        : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t\t('uint8', 'int')         : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t159.9s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 166.46s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\learner.pkl\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.03555547657865836, 'subsample': 0.5068699653762285, 'colsample_bytree': 0.7656757857728277}],\n",
            "}\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\utils\\data\\X.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\utils\\data\\y.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\utils\\data\\X_val.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\utils\\data\\y_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tXGBoost: \t{'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.03555547657865836, 'subsample': 0.5068699653762285, 'colsample_bytree': 0.7656757857728277, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:1.60476\tvalidation_0-_f1_weighted:-0.32547\n",
            "[50]\tvalidation_0-mlogloss:1.46532\tvalidation_0-_f1_weighted:-0.39349\n",
            "[100]\tvalidation_0-mlogloss:1.40555\tvalidation_0-_f1_weighted:-0.42005\n",
            "[105]\tvalidation_0-mlogloss:1.40098\tvalidation_0-_f1_weighted:-0.42307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\XGBoost\\model.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "\t0.4231\t = Validation score   (f1_weighted)\n",
            "\t246.54s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "\t85413.4\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\trainer.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\utils\\attr\\XGBoost\\y_pred_proba_val.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 12\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\WeightedEnsemble_L2\\utils\\model_template.pkl\n",
            "Ensemble size: 1\n",
            "Ensemble weights: \n",
            "[1.]\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\WeightedEnsemble_L2\\utils\\oof.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.4231\t = Validation score   (f1_weighted)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "\t82444.1\t = Inference  throughput (rows/s | 28304 batch size)\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\trainer.pkl\n",
            "AutoGluon training complete, total runtime = 418.38s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 82444.1 rows/s (28304 batch size)\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\trainer.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\learner.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\predictor.pkl\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\version.txt with contents \"1.2\"\n",
            "Saving c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\")\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\XGBoost\\model.pkl\n",
            "Loading: c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_223949\\models\\WeightedEnsemble_L2\\model.pkl\n",
            "[I 2025-01-01 23:47:16,228] Trial 19 finished with value: inf and parameters: {'n_estimators': 106, 'max_depth': 5, 'learning_rate': 0.03555547657865836, 'subsample': 0.5068699653762285, 'colsample_bytree': 0.7656757857728277}. Best is trial 0 with value: inf.\n",
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_224716\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "Memory Avail:       20.74 GB / 39.32 GB (52.8%)\n",
            "Disk Space Avail:   152.52 GB / 449.47 GB (33.9%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial failed with exception: 'piezo_groundwater_level_category'\n",
            "Best hyperparameters: {'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.28333206115755916, 'subsample': 0.5198366253240017, 'colsample_bytree': 0.8522255121629868}\n",
            "Best score: inf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_224716\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    27393.01 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (29.9% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 29.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 33 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 20 | ['__nlp__.265', '__nlp__.327', '__nlp__.alpes', '__nlp__.centre', '__nlp__.conseil', ...]\n",
            "\t229.2s = Fit runtime\n",
            "\t87 features in original data used to generate 126 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1541.26 MB (5.4% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 235.93s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGBoost': [{'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.28333206115755916, 'subsample': 0.5198366253240017, 'colsample_bytree': 0.8522255121629868}],\n",
            "}\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "Unknown model type specified in hyperparameters: 'XGBoost'. Valid model types: ['RF', 'XT', 'KNN', 'GBM', 'CAT', 'XGB', 'NN_TORCH', 'LR', 'FASTAI', 'TRANSF', 'AG_TEXT_NN', 'AG_IMAGE_NN', 'AG_AUTOMM', 'FT_TRANSFORMER', 'TABPFN', 'TABPFNMIX', 'FASTTEXT', 'ENS_WEIGHTED', 'SIMPLE_ENS_WEIGHTED', 'IM_RULEFIT', 'IM_GREEDYTREE', 'IM_FIGS', 'IM_HSTREE', 'IM_BOOSTEDRULES', 'VW', 'DUMMY']",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 44\u001b[0m\n\u001b[0;32m     40\u001b[0m best_hyperparameters \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m'\u001b[39m: study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m     42\u001b[0m }\n\u001b[0;32m     43\u001b[0m final_predictor \u001b[38;5;241m=\u001b[39m TabularPredictor(label\u001b[38;5;241m=\u001b[39mlabel_column, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43mfinal_predictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_hyperparameters\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1299\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;66;03m# keep track of the fit strategy used for future calls\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_strategy \u001b[38;5;241m=\u001b[39m fit_strategy\n\u001b[1;32m-> 1299\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_post_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1305\u001b[0m, in \u001b[0;36mTabularPredictor._fit\u001b[1;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001b[0m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, ag_fit_kwargs: \u001b[38;5;28mdict\u001b[39m, ag_post_fit_kwargs: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mag_fit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_fit(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag_post_fit_kwargs)\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[1;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearner is already fit.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_fit_input(X\u001b[38;5;241m=\u001b[39mX, X_val\u001b[38;5;241m=\u001b[39mX_val, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:131\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[1;34m(self, X, X_val, X_test, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_metric \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39meval_metric\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m--> 131\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit_trainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrainer_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_trainer(trainer\u001b[38;5;241m=\u001b[39mtrainer)\n\u001b[0;32m    147\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:135\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m log_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m20\u001b[39m, log_str)\n\u001b[1;32m--> 135\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_multi_and_ensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:3238\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[1;34m(self, X, y, X_val, y_val, X_test, y_test, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[0;32m   3236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_rows_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_test)\n\u001b[0;32m   3237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_cols_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m-> 3238\u001b[0m model_names_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_multi_levels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3240\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3243\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3245\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_stack_levels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3253\u001b[0m     \u001b[38;5;66;03m# TODO v1.0: Add toggle to raise exception if no models trained\u001b[39;00m\n\u001b[0;32m   3254\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: AutoGluon did not successfully train any models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:493\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[1;34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size, callbacks)\u001b[0m\n\u001b[0;32m    491\u001b[0m         core_kwargs_level[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m core_kwargs_level\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_limit_core)\n\u001b[0;32m    492\u001b[0m         aux_kwargs_level[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m aux_kwargs_level\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_limit_aux)\n\u001b[1;32m--> 493\u001b[0m     base_model_names, aux_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_new_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcore_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcore_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43maux_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maux_kwargs_level\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_full_weighted_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m     model_names_fit \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m base_model_names \u001b[38;5;241m+\u001b[39m aux_models\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(model_names_fit) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:688\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[1;34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001b[0m\n\u001b[0;32m    686\u001b[0m     core_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m core_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name_suffix\n\u001b[0;32m    687\u001b[0m     aux_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m aux_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_suffix\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name_suffix\n\u001b[1;32m--> 688\u001b[0m core_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_new_level_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_unlabeled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_unlabeled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_limit_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcore_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m aux_models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_weighted_ensemble:\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:803\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[1;34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, fit_strategy, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m     ensemble_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: base_model_names,\n\u001b[0;32m    790\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_paths_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m: base_model_paths,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: level \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m    795\u001b[0m     }\n\u001b[0;32m    796\u001b[0m     get_models_kwargs\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    798\u001b[0m             ag_args_ensemble\u001b[38;5;241m=\u001b[39mag_args_ensemble,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    801\u001b[0m         )\n\u001b[0;32m    802\u001b[0m     )\n\u001b[1;32m--> 803\u001b[0m models, model_args_fit \u001b[38;5;241m=\u001b[39m \u001b[43mget_models_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mget_models_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_args_fit:\n\u001b[0;32m    805\u001b[0m     hyperparameter_tune_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    806\u001b[0m         model_name: model_args_fit[model_name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameter_tune_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_args_fit\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameter_tune_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_args_fit[model_name]\n\u001b[0;32m    809\u001b[0m     }\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:31\u001b[0m, in \u001b[0;36mAutoTrainer.construct_model_templates\u001b[1;34m(self, hyperparameters, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m     ag_args_fit \u001b[38;5;241m=\u001b[39m ag_args_fit\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     29\u001b[0m     ag_args_fit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantile_levels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m quantile_levels\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_preset_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproblem_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mag_args_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_args_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_model_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_model_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\trainer\\model_presets\\presets.py:250\u001b[0m, in \u001b[0;36mget_preset_models\u001b[1;34m(path, problem_type, eval_metric, hyperparameters, level, ensemble_type, ensemble_kwargs, ag_args_fit, ag_args, ag_args_ensemble, name_suffix, default_priorities, invalid_model_names, included_model_types, excluded_model_types, hyperparameter_preprocess_func, hyperparameter_preprocess_kwargs, silent)\u001b[0m\n\u001b[0;32m    248\u001b[0m     model_cfgs_to_process\u001b[38;5;241m.\u001b[39mappend(model_cfg)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_cfg \u001b[38;5;129;01min\u001b[39;00m model_cfgs_to_process:\n\u001b[1;32m--> 250\u001b[0m     model_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mclean_model_cfg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_args_ensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_args_ensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mag_args_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag_args_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproblem_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m     model_cfg[AG_ARGS][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model_cfg[AG_ARGS]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_priorities\u001b[38;5;241m.\u001b[39mget(model_type, DEFAULT_CUSTOM_MODEL_PRIORITY))\n\u001b[0;32m    259\u001b[0m     model_priority \u001b[38;5;241m=\u001b[39m model_cfg[AG_ARGS][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpriority\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\JLASSI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autogluon\\tabular\\trainer\\model_presets\\presets.py:308\u001b[0m, in \u001b[0;36mclean_model_cfg\u001b[1;34m(model_cfg, model_type, ag_args, ag_args_ensemble, ag_args_fit, problem_type)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(model_type):\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m MODEL_TYPES:\n\u001b[1;32m--> 308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model type specified in hyperparameters: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Valid model types: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(MODEL_TYPES\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    309\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m MODEL_TYPES[model_type]\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(model_type, AbstractModel):\n",
            "\u001b[1;31mAssertionError\u001b[0m: Unknown model type specified in hyperparameters: 'XGBoost'. Valid model types: ['RF', 'XT', 'KNN', 'GBM', 'CAT', 'XGB', 'NN_TORCH', 'LR', 'FASTAI', 'TRANSF', 'AG_TEXT_NN', 'AG_IMAGE_NN', 'AG_AUTOMM', 'FT_TRANSFORMER', 'TABPFN', 'TABPFNMIX', 'FASTTEXT', 'ENS_WEIGHTED', 'SIMPLE_ENS_WEIGHTED', 'IM_RULEFIT', 'IM_GREEDYTREE', 'IM_FIGS', 'IM_HSTREE', 'IM_BOOSTEDRULES', 'VW', 'DUMMY']"
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "label_column ='piezo_groundwater_level_category'\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters for XGBoost\n",
        "    hyperparameters = {\n",
        "        \n",
        "        'GBM': {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 10, 50),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "        # Add additional hyperparameters if needed, based on GBM's supported parameters\n",
        "            },\n",
        "        'XGB': {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Train TabularPredictor\n",
        "    predictor = TabularPredictor(label=label_column, eval_metric='f1_weighted')\n",
        "    try:\n",
        "        predictor.fit(train_data=X_train, hyperparameters=hyperparameters, verbosity=3)\n",
        "        # Evaluate predictions\n",
        "        predictions = predictor.predict(X_test)\n",
        "        score = predictor.evaluate_predictions(y_true=X_test[label_column], y_pred=predictions)\n",
        "        return -score['f1_weighted']  # Optuna minimizes, so return negative metric\n",
        "    except Exception as e:\n",
        "        print(f\"Trial failed with exception: {e}\")\n",
        "        return float('inf')  # Return a high value for failed trials\n",
        "\n",
        "\n",
        "# Create the Optuna study\n",
        "study = optuna.create_study(direction='maximize')  # Maximize f1_weighted\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.28333206115755916, 'subsample': 0.5198366253240017, 'colsample_bytree': 0.8522255121629868}\n",
            "Best score: inf\n"
          ]
        }
      ],
      "source": [
        "# Print the best parameters and score\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best score:\", study.best_value)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels\\ag-20250101_225659\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.11.7\n",
            "Operating System:   Windows\n",
            "Platform Machine:   AMD64\n",
            "Platform Version:   10.0.22631\n",
            "CPU Count:          12\n",
            "Memory Avail:       14.42 GB / 39.32 GB (36.7%)\n",
            "Disk Space Avail:   148.42 GB / 449.47 GB (33.0%)\n",
            "===================================================\n",
            "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
            "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
            "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
            "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
            "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
            "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
            "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
            "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (2830316 samples, 8759.45 MB).\n",
            "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_225659\"\n",
            "Train Data Rows:    2830316\n",
            "Train Data Columns: 94\n",
            "Label Column:       piezo_groundwater_level_category\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['High', 'Very High', 'Very Low', 'Low', 'Average']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    20969.62 MB\n",
            "\tTrain Data (Original)  Memory Usage: 8183.23 MB (39.0% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 39.0% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 313\n",
            "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
            "\t\tReducing Vectorizer vocab size from 313 to 22 to avoid OOM error\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 2): ['hydro_method_code', 'hydro_method_label']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 5): ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', []) : 5 | ['piezo_station_department_name', 'piezo_station_bss_id', 'piezo_bss_code', 'piezo_continuity_name', 'piezo_measure_nature_name']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 55 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_continuity_code', ...]\n",
            "\t\t('int', [])          :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('object', [])       : 23 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('object', ['text']) :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    : 22 | ['piezo_station_department_code', 'piezo_station_commune_code_insee', 'piezo_station_bdlisa_codes', 'piezo_station_bss_code', 'piezo_station_commune_name', ...]\n",
            "\t\t('category', ['text_as_category'])  :  2 | ['piezo_station_pe_label', 'piezo_producer_name']\n",
            "\t\t('float', [])                       : 54 | ['piezo_station_investigation_depth', 'piezo_station_altitude', 'piezo_station_longitude', 'piezo_station_latitude', 'piezo_producer_code', ...]\n",
            "\t\t('int', [])                         :  7 | ['meteo_id', 'meteo_altitude', 'hydro_status_code', 'hydro_qualification_code', 'year', ...]\n",
            "\t\t('int', ['binned', 'text_special']) : 19 | ['piezo_station_pe_label.char_count', 'piezo_station_pe_label.word_count', 'piezo_station_pe_label.capital_ratio', 'piezo_station_pe_label.lower_ratio', 'piezo_station_pe_label.digit_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  2 | ['piezo_continuity_code', 'hydro_hydro_quantity_elab']\n",
            "\t\t('int', ['text_ngram'])             : 15 | ['__nlp__.327', '__nlp__.conseil', '__nlp__.conseil gnral', '__nlp__.de', '__nlp__.de la', ...]\n",
            "\t199.7s = Fit runtime\n",
            "\t87 features in original data used to generate 121 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1514.26 MB (5.8% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 206.87s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 2802012, Val Rows: 28304\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'XGB': [{'n_estimators': 178, 'max_depth': 6, 'learning_rate': 0.28333206115755916, 'subsample': 0.5198366253240017, 'colsample_bytree': 0.8522255121629868}],\n",
            "}\n",
            "Fitting 1 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: XGBoost ...\n",
            "\tWarning: Potentially not enough memory to safely train model. Estimated to require 13.201 GB out of 15.656 GB available memory (84.319%)... (100.000% of avail memory is the max safe size)\n",
            "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.17 to avoid the warning)\n",
            "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
            "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
            "\t0.6473\t = Validation score   (f1_weighted)\n",
            "\t380.43s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\tEnsemble Weights: {'XGBoost': 1.0}\n",
            "\t0.6473\t = Validation score   (f1_weighted)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 592.67s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 50085.7 rows/s (28304 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\JLASSI\\Downloads\\HAck\\AutogluonModels\\ag-20250101_225659\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x25b23f62c50>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract best hyperparameters for each model type\n",
        "best_hyperparameters = {\n",
        "    'XGB': {\n",
        "        'n_estimators': study.best_params.get('n_estimators', 100),\n",
        "        'max_depth': study.best_params.get('max_depth', 6),\n",
        "        'learning_rate': study.best_params.get('learning_rate', 0.1),\n",
        "        'subsample': study.best_params.get('subsample', 1.0),\n",
        "        'colsample_bytree': study.best_params.get('colsample_bytree', 1.0),\n",
        "    },\n",
        "    'GBM': {\n",
        "        'n_estimators': study.best_params.get('n_estimators', 100),\n",
        "        'early_stopping_rounds': study.best_params.get('early_stopping_rounds', 20),\n",
        "        'learning_rate': study.best_params.get('learning_rate', 0.1),\n",
        "    },\n",
        "}\n",
        "\n",
        "# Train the final model with the best hyperparameters\n",
        "final_predictor = TabularPredictor(label=label_column, eval_metric='f1_weighted')\n",
        "final_predictor.fit(train_data=X_train, hyperparameters=best_hyperparameters, verbosity=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = final_predictor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy_score = np.mean(y_test==predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5222886480543448"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy_score"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "nG-XRnHDAyZj"
      ],
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
